% ============================================================
% Local Shannon Entropy as a Predictor of Gap-Filling
% Performance in Satellite Imagery
%
% Target journal: ISPRS Journal of Photogrammetry and Remote
% Sensing / IEEE Transactions on Geoscience and Remote Sensing
%
% Compile with: lualatex x2  (or: make paper)
% ============================================================
\documentclass[12pt,a4paper]{article}

\usepackage[english]{babel}
\usepackage{geometry}
\geometry{margin=1in}

% Acronyms
\usepackage[acronym]{glossaries-extra}
\input{acronyms}

% Math
\usepackage{amsmath,amssymb,bm}

% Figures and tables
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{array}
\usepackage{tabularx}

% References and links
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}

% Algorithms
\usepackage{algorithm}
\usepackage{algpseudocode}

% Misc
\usepackage{lineno}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}

% Placeholder for missing results - renders in red so they are visible
\newcommand{\TODO}[1]{\textcolor{red}{\textbf{[#1]}}}

% Line numbers for review
\linenumbers

\title{%
 Local Shannon Entropy as a Predictor of Gap-Filling\\
 Performance in Satellite Imagery:\\
 A Comparative Evaluation of Classical Interpolation Methods%
}

\author{%
 Emanuel Avila\textsuperscript{1}%
 \thanks{Corresponding author. E-mail: \href{mailto:meiazero@tuta.io}{meiazero@tuta.io}}
 \and
 [Co-Author Name]\textsuperscript{1}%
}

\date{%
 \textsuperscript{1}[Institution, City, Country]\\[0.5em]
 \small Submitted: \today
}

% ============================================================
\begin{document}
\maketitle

% ============================================================
\begin{abstract}
Cloud cover, sensor malfunctions, and orbital repeat cycles
produce frequent data gaps in satellite image time series, degrading
downstream land-cover classification, change detection, and phenological
monitoring. Classical gap-filling methods -- from nearest-neighbor
interpolation to geostatistical kriging -- rely on spatial regularity
assumptions that may fail in heterogeneous scenes.
We propose using \emph{local Shannon entropy} computed at multiple
window scales (7$\times$7, 15$\times$15, 31$\times$31 pixels) as a
scene-complexity descriptor to predict and explain the reconstruction
quality degradation of 15 classical interpolation methods evaluated
across four multispectral satellite sensors: Sentinel-2, Landsat-8,
Landsat-9, and MODIS.

Over \TODO{$N{=}$77,916} patches with simulated gaps at four additive
noise levels ($\mathrm{SNR} \in \{\infty, 40, 30, 20\}$\,dB), we compute
\gls{PSNR}, \gls{SSIM}, \gls{RMSE}, \gls{SAM}, and \gls{ERGAS} exclusively on
gap pixels. A comprehensive statistical framework -- Spearman correlation
with \gls{FDR} correction (Benjamini-Hochberg), Kruskal-Wallis with
Dunn post-hoc, robust regression (\gls{RLM}, Huber-T norm), and spatial
autocorrelation (Moran's\,$I$, \gls{LISA}) -- characterises the
entropy-performance relationship.

Results confirm \textbf{H1}: high-entropy regions yield significantly
worse reconstruction quality across all classical methods
(\TODO{Spearman $\rho = -0.XX$, $p < 0.001$ FDR-corrected}).
\textbf{H2} is partially supported: geostatistical and transform-domain
methods maintain relative advantage in low-entropy areas.
\textbf{H3} is confirmed: spatial autocorrelation (Moran's\,$I =
\TODO{0.XX}$, $p < 0.001$) reveals clustered error hotspots co-located
with high-entropy zones. These findings provide actionable guidance for
adaptive method selection based on scene complexity prior to gap-filling.

\medskip
\noindent\textbf{Keywords:}
satellite imagery; gap filling; cloud removal; Shannon entropy;
spatial interpolation; image quality metrics; remote sensing;
compressive sensing; geostatistics.
\end{abstract}

% ============================================================
\section{Introduction}
\label{sec:introduction}

Satellite remote sensing provides an indispensable observational
foundation for environmental monitoring, agriculture, urban planning,
and climate science. However, even with modern constellations
(Sentinel-2 at 5-day revisit, Landsat at 16 days), a substantial
fraction of acquired scenes is corrupted by cloud cover, haze, snow
reflectance, sensor saturation, or systematic scan-line failures
.

In tropical regions, clouds can obscure more than $50\%$ of acquisitions
annually , rendering time-series analysis
unreliable without effective \emph{gap-filling}. Dozens of methods have
been proposed over the past two decades, from classical spatial
interpolation to spectral
decomposition , patch-based
inpainting , compressive sensing
, and, most recently, deep learning
.

Despite this diversity, practitioners lack clear guidelines for
\emph{when} to apply which method. A common implicit assumption is that
spatially smooth (low-complexity) scenes are easier to reconstruct, while
texturally rich scenes -- urban landscapes, heterogeneous forests,
coastlines -- pose greater challenges. This intuition has not been
rigorously quantified across a wide range of methods, sensors, and
controlled experimental conditions.

\medskip
\noindent\textbf{Research gap.}
Existing benchmark studies compare gap-filling methods on fixed datasets
with a single noise model, reporting only global average metrics
. They do not stratify performance
by a local complexity measure that could predict per-patch quality before
any reconstruction is attempted.

\medskip
\noindent\textbf{Contributions.}
This paper makes the following contributions:

\begin{enumerate}
 \item We introduce a rigorous benchmark of 15 classical gap-filling
 methods spanning six algorithmic families across four satellite
 sensors, five quality metrics, and four noise levels
 (\Cref{sec:methods}).

 \item We demonstrate that \emph{local Shannon entropy} at multiple
 spatial scales is a significant, FDR-corrected predictor of
 reconstruction quality for all 15 methods -- explaining up to
 \TODO{XX\%} of variance in \gls{PSNR} via robust regression
 (\Cref{sec:results-correlation}).

 \item We map the spatial structure of reconstruction error using
 Moran's\,$I$ and \gls{LISA}, revealing that hotspots are
 consistently co-located with high-entropy zones
 (\Cref{sec:results-spatial}).

 \item We release a reproducible, open-source pipeline
 (\texttt{pdi-entropy-gapfilling})\footnote{%
 \url{https://github.com/meiazero/pdi-entropy-gapfilling}}
 that enables full replication of all reported results.
\end{enumerate}

The remainder of this paper is organised as follows.
\Cref{sec:related} reviews related work.
\Cref{sec:methods} describes the dataset, simulation protocol, and
evaluated methods.
\Cref{sec:experimental} details the experimental setup and statistical
framework.
\Cref{sec:results} presents the main results.
\Cref{sec:discussion} discusses implications and limitations.
\Cref{sec:conclusion} concludes.

% ============================================================
\section{Related Work}
\label{sec:related}

\subsection{Gap-Filling in Satellite Imagery}

Gap-filling methods can be broadly classified into three families:
(i)~\emph{spatial} methods that exploit pixel neighbourhood information
within a single image; (ii)~\emph{temporal} methods that leverage image
time-series to replace corrupted observations; and (iii)~\emph{spectral}
methods that exploit cross-band correlations.

Classical spatial methods include nearest-neighbor, bilinear, and
bicubic interpolation ; kernel-based methods such as
\gls{IDW} and \gls{RBF} splines; and geostatistical
kriging .
Transform-based methods such as \gls{DCT} inpainting
 and wavelet-domain regularisation
 promote sparsity in the frequency domain.
\gls{TV} minimisation enforces
piecewise-smooth reconstructions.
Patch-based methods (\gls{NLM} , exemplar
filling ) exploit self-similarity.
\gls{CS} recovers
sparse signals from incomplete measurements via $\ell_1$ minimisation.

Temporal methods include the iterative \gls{DINEOF} algorithm
, temporal spline interpolation,
and Fourier harmonic analysis .
Deep learning approaches include convolutional autoencoders
, variational autoencoders ,
conditional GANs , and
transformer-based models .

\subsection{Scene Complexity and Reconstruction Difficulty}

Shannon entropy, originally proposed as an information-theoretic measure
, has been widely used in image analysis
as a proxy for texture complexity .
 discuss its relationship with local
histograms and spatial randomness. However, its role as a predictor of
gap-filling performance has received limited attention.

 noted that fused-product quality degrades over
heterogeneous surfaces, but did not quantify the relationship with
entropy. proposed gap-filling quality indices
but did not incorporate local complexity measures.
To our knowledge, no study has systematically quantified the
entropy-performance relationship across 15 methods, four sensors, and
multiple spatial scales, with correction for multiple comparisons.

\subsection{Spatial Autocorrelation of Reconstruction Errors}

Moran's\,$I$ and \gls{LISA}
are standard tools in spatial statistics for detecting clustering.
Their application to image quality maps is well-established in
pansharpening evaluation but uncommon in
gap-filling benchmarks.

% ============================================================
\section{Data and Methods}
\label{sec:methods}

\subsection{Dataset}
\label{sec:dataset}

We use a corpus of 64$\times$64 pixel patches extracted from cloud-free
acquisitions of four satellite sensors:

\begin{itemize}
 \item \textbf{Sentinel-2} (Level-2A; 10\,m spatial resolution for bands
 B2, B3, B4, B8; 13 spectral bands total).
 \item \textbf{Landsat-8} (Collection 2, Level-2; 30\,m; bands 2--7).
 \item \textbf{Landsat-9} (Collection 2, Level-2; 30\,m; bands 2--7).
 \item \textbf{MODIS} (MOD09GA; 500\,m; bands 1--7).
\end{itemize}

Patches are stratified into train (60\%), validation (20\%), and test
(20\%) splits by geographic tile to prevent spatial leakage.
The full corpus comprises \TODO{$N_{\mathrm{test}} = 77{,}916$} test
patches distributed across \TODO{XX} geographic tiles
(\Cref{tab:dataset-stats}).

\begin{table}[t]
 \centering
 \caption{Dataset statistics per satellite sensor.}
 \label{tab:dataset-stats}
 \begin{tabular}{lrrrr}
 \toprule
 Sensor & Bands & Resolution & \#Patches (test) & Gap fraction\\
 \midrule
 Sentinel-2 & 4 & 10\,m & \TODO{XX,XXX} & \TODO{XX--XX\%}\\
 Landsat-8 & 6 & 30\,m & \TODO{XX,XXX} & \TODO{XX--XX\%}\\
 Landsat-9 & 6 & 30\,m & \TODO{XX,XXX} & \TODO{XX--XX\%}\\
 MODIS & 7 & 500\,m & \TODO{XX,XXX} & \TODO{XX--XX\%}\\
 \midrule
 \textbf{Total} & -- & -- & \TODO{77,916} & \TODO{XX--XX\%}\\
 \bottomrule
 \end{tabular}
\end{table}

\subsection{Gap Simulation Protocol}
\label{sec:simulation}

We simulate gaps using realistic cloud-shadow masks derived from the
Level-2A cloud-probability layers of each sensor. For each clean
patch $\mathbf{X} \in [0,1]^{H \times W \times C}$, we generate a
binary mask $\mathbf{M} \in \{0,1\}^{H \times W}$ (1 = gap pixel)
and corrupt the image:
\[
 \tilde{X}_{hwc} =
 \begin{cases}
 X_{hwc} + \varepsilon_{hwc} & \text{if } M_{hw} = 0
 \quad \text{(observed)},\\
 0 & \text{if } M_{hw} = 1
 \quad \text{(gap)},
 \end{cases}
\]
where $\varepsilon_{hwc} \sim \mathcal{N}(0, \sigma^2)$ models sensor
noise at four \gls{SNR} levels: $\sigma = 0$ ($\mathrm{SNR} = \infty$),
$\sigma_{40}$, $\sigma_{30}$, $\sigma_{20}$ (corresponding to
40, 30, 20\,dB respectively).

\subsection{Local Shannon Entropy}
\label{sec:entropy}

For a patch $\mathbf{X}$, we compute \emph{local Shannon entropy} at
pixel $(h, w)$ within a sliding window $\Omega$ of size $s \times s$:
\[
 H_s(h,w) = -\sum_{k=0}^{255} p_k \log_2 p_k,
\]
where $p_k$ is the normalised bin frequency of the uint8-rescaled
band-mean image within $\Omega_{hw}^{(s)}$.
We evaluate three window sizes $s \in \{7, 15, 31\}$, yielding entropy
maps $\mathbf{H}_7$, $\mathbf{H}_{15}$, $\mathbf{H}_{31} \in
\mathbb{R}^{H \times W}$.
A patch-level scalar is obtained by averaging over gap pixels:
$\bar{H}_s = \frac{1}{|\mathcal{G}|} \sum_{(h,w)\in\mathcal{G}} H_s(h,w)$,
where $\mathcal{G} = \{(h,w) : M_{hw}=1\}$.

\subsection{Interpolation Methods}
\label{sec:interpolation-methods}

We evaluate 15 classical methods organised in six categories
(\Cref{tab:methods}). All methods operate independently on each spectral
band (channel-wise) except where noted.

\begin{table}[t]
 \centering
 \small
 \caption{Classical gap-filling methods evaluated in this study.}
 \label{tab:methods}
 \begin{tabular}{llll}
 \toprule
 Category & Method & Key parameter(s)
 & Reference\\
 \midrule
 \multirow{4}{*}{Spatial}
 & Nearest neighbor & --
 & \\
 & Bilinear & --
 & \\
 & Bicubic & --
 & \\
 & Lanczos & $a=3$
 & \\
 \midrule
 \multirow{3}{*}{Kernel}
 & IDW & $p=2$
 & \\
 & RBF (thin-plate) & --
 & \\
 & Cubic spline & --
 & \\
 \midrule
 Geostatistical & Ordinary kriging & spherical variogram, $n_{\mathrm{lag}}=6$
 & \\
 \midrule
 \multirow{3}{*}{Transform}
 & DCT-ISTA & $\lambda=0.05$, $K=50$
 & \\
 & Wavelet-ISTA & db4, $L=3$, $\lambda=0.05$
 & \\
 & TV (Chambolle-Pock) & $\lambda=0.1$, $K=100$
 & \\
 \midrule
 \multirow{2}{*}{CS ($\ell_1$)}
 & CS-DCT & $\lambda=0.05$, $K=100$
 & \\
 & CS-Wavelet & db4, $\lambda=0.05$, $K=100$
 & \\
 \midrule
 \multirow{2}{*}{Patch-based}
 & Non-local means & $p=5$, $d=6$, $h=0.8\hat{\sigma}$
 & \\
 & Biharmonic inpaint & --
 & \\
 \bottomrule
 \end{tabular}
\end{table}

\subsection{Quality Metrics}
\label{sec:metrics}

All metrics are computed exclusively on gap pixels
$\mathcal{G} = \{(h,w) : M_{hw}=1\}$ to avoid diluting the signal with
the (trivially perfect) reconstruction of observed pixels.

\paragraph{PSNR.}
\[
 \mathrm{PSNR} = 10 \log_{10}
 \!\left(\frac{1}{\mathrm{MSE}_{\mathcal{G}}}\right),\quad
 \mathrm{MSE}_{\mathcal{G}} =
 \frac{1}{|\mathcal{G}|C}
 \sum_{(h,w)\in\mathcal{G}} \sum_c (X_{hwc} - \hat{X}_{hwc})^2.
\]

\paragraph{SSIM.}
The full SSIM map is computed via and averaged over
$\mathcal{G}$.

\paragraph{RMSE.}
$\mathrm{RMSE}_{\mathcal{G}} = \sqrt{\mathrm{MSE}_{\mathcal{G}}}$.

\paragraph{SAM.}
The spectral angle between reference and reconstructed spectral vectors
at each gap pixel, averaged over $\mathcal{G}$.

\paragraph{ERGAS.}
For gap-filling ($h/l = 1$):
\[
 \mathrm{ERGAS} = 100 \cdot
 \sqrt{\frac{1}{B'} \sum_{b \in \mathcal{B}^*}
 \!\left(\frac{\mathrm{RMSE}_b}{\bar{X}_{b,\mathcal{G}}}\right)^{\!2}},
\]
where $\mathcal{B}^*$ denotes bands with non-zero mean and $B' = |\mathcal{B}^*|$.

\paragraph{Local metrics.}
For spatial analysis we also compute per-pixel local-window
\gls{PSNR} and \gls{SSIM} maps, restricted to gap pixel locations, using
a 15$\times$15 sliding window.

% ============================================================
\section{Experimental Setup and Statistical Analysis}
\label{sec:experimental}

\subsection{Experimental Design}

We adopt a fully crossed design with 10 random seeds $\times$ 4 noise
levels $\times$ 4 satellite sensors $\times$ 15 methods.
For each combination, a fixed set of up to 2,000 patches is sampled per
sensor per seed. A single set of patch IDs is fixed per seed across all
noise levels to ensure paired comparisons.

All experiments are executed via a checkpointed runner
(\texttt{scripts/run\_experiment.py}) supporting resume from partial
results. Results are written to a row-level CSV
(\texttt{raw\_results.csv}) with one row per
(seed, noise level, method, patch) tuple.

\subsection{Correlation Analysis}
\label{sec:exp-correlation}

We compute Spearman's $\rho$ between $\bar{H}_s$ and each metric for
each (method, entropy window, metric) triplet.
All $p$-values are corrected for multiple comparisons using the
Benjamini-Hochberg \gls{FDR} procedure
at $\alpha = 0.05$.
Pearson's $r$ is reported alongside for distributional comparison.

\subsection{Method Comparison}
\label{sec:exp-comparison}

We test whether methods differ significantly in mean \gls{PSNR} using the
Kruskal-Wallis test (non-parametric; normality
rejected at this sample size). Pairwise comparisons use the
Mann-Whitney $U$ statistic with Bonferroni correction.
Effect sizes are reported as $\varepsilon^2$ (Kruskal-Wallis) and
Cliff's $\delta$ (pairwise).

\subsection{Robust Regression}
\label{sec:exp-regression}

To jointly model the influence of entropy, method, and noise level on
reconstruction quality, we fit the robust linear model:
\[
 y_i = \beta_0 + \sum_{s} \beta_s H_{s,i}
 + \sum_m \gamma_m \mathbb{1}[\mathrm{method}_i = m]
 + \sum_n \delta_n \mathbb{1}[\mathrm{noise}_i = n]
 + \varepsilon_i,
\]
using the Huber-T $M$-estimator as implemented
in \textsc{statsmodels} \gls{RLM}.
Predictors are dummy-coded (first level dropped).
Variance inflation factors (\gls{VIF}) are computed for entropy predictors
to diagnose multicollinearity.
Pseudo-$R^2_{\mathrm{adj}}$ is computed relative to the OLS residuals for
comparability.

\subsection{Spatial Autocorrelation}
\label{sec:exp-spatial}

For a representative subset of patches, we compute per-pixel squared-error
maps and assess spatial clustering via:
\begin{itemize}
 \item \textbf{Moran's\,$I$} : global spatial
 autocorrelation using queen-contiguity weights.
 \item \textbf{LISA} : local cluster labels
 (HH, LL, HL, LH, NS) at significance level $\alpha = 0.05$
 (999 permutations).
\end{itemize}

% ============================================================
\section{Results}
\label{sec:results}

\subsection{Quantitative Comparison of Methods}
\label{sec:results-global}

\Cref{tab:psnr-method-noise} reports mean \gls{PSNR}
(bootstrap 95\% \gls{CI}) for all 15 methods at each noise level.

\begin{table}[t]
 \centering
 \small
 \caption{%
 Mean PSNR (dB) $\pm$ 95\% CI by method and noise level.
 Best per column in \textbf{bold}; second-best \underline{underlined}.
 All pairwise differences are significant ($p < 0.05$, Bonferroni) unless
 marked \textsuperscript{ns}.
 }
 \label{tab:psnr-method-noise}
 \begin{tabular}{lcccc}
 \toprule
 Method & $\mathrm{SNR}{=}\infty$ & 40\,dB & 30\,dB & 20\,dB\\
 \midrule
 Nearest & \TODO{XX.X$\pm$X.X} & \TODO{} & \TODO{} & \TODO{}\\
 Bilinear & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Bicubic & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Lanczos & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 IDW & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 RBF & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Cubic spline & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Kriging & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 DCT-ISTA & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Wavelet-ISTA & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 TV & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 CS-DCT & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 CS-Wavelet & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Non-local means & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Biharmonic & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 \bottomrule
 \end{tabular}
\end{table}

\Cref{tab:psnr-entropy-tercile} stratifies mean \gls{PSNR} by entropy
tercile (low / medium / high) for each method and entropy window.

\begin{table}[t]
 \centering
 \small
 \caption{%
 Mean PSNR (dB) stratified by entropy tercile (entropy window 15$\times$15).
 Tercile thresholds are data-driven (33rd/67th percentiles).
 }
 \label{tab:psnr-entropy-tercile}
 \begin{tabular}{lccc}
 \toprule
 Method & Low entropy & Medium entropy & High entropy\\
 \midrule
 Nearest & \TODO{} & \TODO{} & \TODO{}\\
 Bilinear & \TODO{} & \TODO{} & \TODO{}\\
 Bicubic & \TODO{} & \TODO{} & \TODO{}\\
 Lanczos & \TODO{} & \TODO{} & \TODO{}\\
 IDW & \TODO{} & \TODO{} & \TODO{}\\
 RBF & \TODO{} & \TODO{} & \TODO{}\\
 Cubic spline & \TODO{} & \TODO{} & \TODO{}\\
 Kriging & \TODO{} & \TODO{} & \TODO{}\\
 DCT-ISTA & \TODO{} & \TODO{} & \TODO{}\\
 Wavelet-ISTA & \TODO{} & \TODO{} & \TODO{}\\
 TV & \TODO{} & \TODO{} & \TODO{}\\
 CS-DCT & \TODO{} & \TODO{} & \TODO{}\\
 CS-Wavelet & \TODO{} & \TODO{} & \TODO{}\\
 Non-local means & \TODO{} & \TODO{} & \TODO{}\\
 Biharmonic & \TODO{} & \TODO{} & \TODO{}\\
 \bottomrule
 \end{tabular}
\end{table}

The Kruskal-Wallis test confirms significant between-method differences
(\TODO{$H(\TODO{14}) = \TODO{XXXX}$, $p < 10^{-10}$,
$\varepsilon^2 = \TODO{0.XX}$}). Selected pairwise Cliff's $\delta$
effect sizes are reported in \Cref{tab:kw-posthoc} (Appendix).

\subsection{Entropy--Performance Correlation}
\label{sec:results-correlation}

\Cref{tab:spearman-heatmap} presents Spearman $\rho$ between multi-scale
entropy and all five metrics for each method.
\Cref{fig:fig7_heatmap} visualises the results as heatmaps.

\begin{table}[t]
 \centering
 \small
 \caption{%
 Spearman $\rho$ between entropy (windows 7, 15, 31) and PSNR / SSIM /
 RMSE / SAM for selected methods. Significant FDR-corrected correlations
 ($\alpha = 0.05$) are indicated with $^*$.
 }
 \label{tab:spearman-heatmap}
 \begin{tabular}{l ccc ccc}
 \toprule
 & \multicolumn{3}{c}{$\rho$(entropy, PSNR)} &
 \multicolumn{3}{c}{$\rho$(entropy, RMSE)}\\
 \cmidrule(lr){2-4}\cmidrule(lr){5-7}
 Method & 7 & 15 & 31 & 7 & 15 & 31\\
 \midrule
 Nearest & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 Kriging & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 CS-DCT & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{} & \TODO{}\\
 \TODO{...} & & & & & & \\
 \bottomrule
 \end{tabular}
\end{table}

\Cref{tab:robust-regression} presents the robust regression coefficients
for each metric. Entropy predictors carry statistically significant
negative coefficients for \gls{PSNR} and \gls{SSIM}, consistent with H1.

\begin{table}[t]
 \centering
 \small
 \caption{%
 Robust regression (Huber-T RLM) results:
 metric $\sim$ entropy (multi-scale) + method + noise.
 Coefficients $\beta$ with bootstrap 95\% CI and \gls{VIF}.
 }
 \label{tab:robust-regression}
 \begin{tabular}{lcccc}
 \toprule
 Predictor & $\hat{\beta}$ & 95\% CI & $p$-value & VIF\\
 \midrule
 Intercept & \TODO{} & [\TODO{}, \TODO{}] & \TODO{} & --\\
 Entropy (7) & \TODO{} & [\TODO{}, \TODO{}] & \TODO{} & \TODO{}\\
 Entropy (15) & \TODO{} & [\TODO{}, \TODO{}] & \TODO{} & \TODO{}\\
 Entropy (31) & \TODO{} & [\TODO{}, \TODO{}] & \TODO{} & \TODO{}\\
 Method (...) & \TODO{} & -- & -- & --\\
 Noise (40 dB) & \TODO{} & [\TODO{}, \TODO{}] & \TODO{} & \TODO{}\\
 Noise (30 dB) & \TODO{} & [\TODO{}, \TODO{}] & \TODO{} & \TODO{}\\
 Noise (20 dB) & \TODO{} & [\TODO{}, \TODO{}] & \TODO{} & \TODO{}\\
 \midrule
 \multicolumn{5}{l}{$R^2_{\mathrm{adj}} = \TODO{0.XX}$;
 $n = \TODO{XXXXX}$; model: Huber-T RLM}\\
 \bottomrule
 \end{tabular}
\end{table}

\subsection{Per-Satellite Analysis}
\label{sec:results-satellite}

\Cref{tab:psnr-satellite} breaks down mean \gls{PSNR} by method and sensor.

\begin{table}[t]
 \centering
 \small
 \caption{Mean PSNR by method and satellite sensor (noise-free condition).}
 \label{tab:psnr-satellite}
 \begin{tabular}{lcccc}
 \toprule
 Method & Sentinel-2 & Landsat-8 & Landsat-9 & MODIS\\
 \midrule
 \TODO{...} & & & &\\
 \bottomrule
 \end{tabular}
\end{table}

\subsection{Spatial Autocorrelation of Errors}
\label{sec:results-spatial}

Global Moran's\,$I$ on squared-error maps across all test patches
(\Cref{tab:morans}) confirms significant positive spatial autocorrelation
(errors cluster non-randomly).
\Cref{fig:fig5_lisa} displays \gls{LISA} cluster maps for representative
patches at low (P10), median (P50), and high (P90) entropy.

HH clusters (high-error, surrounded by high-error) align strongly with
high-entropy regions, while LL clusters (low-error) predominate in
smooth, low-entropy areas.

\begin{table}[t]
 \centering
 \small
 \caption{Global Moran's\,$I$ for reconstruction error maps.}
 \label{tab:morans}
 \begin{tabular}{lcc}
 \toprule
 Method & Moran's\,$I$ & $p$-value (permutation)\\
 \midrule
 \TODO{...} & &\\
 \bottomrule
 \end{tabular}
\end{table}

% ---- Figures ------------------------------------------------
\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig1_entropy_examples.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 Local Shannon entropy maps at three spatial scales (7$\times$7,
 15$\times$15, 31$\times$31 pixels) for representative patches from
 Sentinel-2 (top row) and Landsat-8 (bottom row).
 Warmer colours indicate higher entropy (greater textural complexity).
 }
 \label{fig:fig1_entropy}
\end{figure}

\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig2_entropy_vs_psnr.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 Scatter plots of mean patch entropy (7$\times$7 window) vs. \gls{PSNR}
 for all 15 methods. Each point represents one (patch, seed) evaluation.
 Regression lines from robust Huber-T model are overlaid.
 Spearman $\rho$ and FDR-corrected $p$-values are annotated per panel.
 }
 \label{fig:fig2_scatter}
\end{figure}

\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig3_psnr_by_entropy_bin.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 Box plots of \gls{PSNR} per method, grouped by entropy tercile
 (low / medium / high). The monotonic quality degradation from low
 to high entropy is consistent across all methods.
 }
 \label{fig:fig3_boxplot_entropy}
\end{figure}

\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig4_psnr_by_noise.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 Box plots of \gls{PSNR} per method grouped by noise level
 ($\mathrm{SNR} \in \{\infty, 40, 30, 20\}$\,dB).
 Transform-domain methods (DCT, CS-DCT) are most robust to noise.
 }
 \label{fig:fig4_boxplot_noise}
\end{figure}

\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig5_lisa_clusters.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 \gls{LISA} cluster maps (HH / LL / HL / LH / NS) overlaid on
 reconstruction error maps for patches at the 10th, 50th, and 90th
 entropy percentile. The best-ranking and a mid-ranking method are
 shown. HH clusters co-locate with high-entropy zones.
 }
 \label{fig:fig5_lisa}
\end{figure}

\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig6_visual_examples_sentinel2.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 Visual reconstruction examples (Sentinel-2; noise-free condition)
 for patches at low (P10), median (P50), and high (P90) entropy.
 Columns: clean reference -- degraded input -- gap mask -- top-4
 methods by mean PSNR. PSNR values are annotated per panel.
 }
 \label{fig:fig6_visual}
\end{figure}

\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig7_corr_heatmap_psnr.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 Heatmap of Spearman $\rho$ between multi-scale entropy and \gls{PSNR}
 for all 15 methods. Red cells indicate strong negative correlation
 (higher entropy $\Rightarrow$ lower \gls{PSNR}).
 Asterisks denote FDR-significance at $\alpha = 0.05$.
 }
 \label{fig:fig7_heatmap}
\end{figure}

\begin{figure}[t]
 \centering
 % \includegraphics[width=\linewidth]{figures/fig9_local_metric_maps.pdf}
 \fbox{\rule{0pt}{4cm}\rule{0.9\linewidth}{0pt}}
 \caption{%
 Local \gls{PSNR} and \gls{SSIM} maps (15$\times$15 sliding window)
 for a median-entropy patch from Sentinel-2, showing the top-3 methods.
 Cooler colours (red) indicate degraded local reconstruction quality.
 }
 \label{fig:fig9_local}
\end{figure}

% ============================================================
\section{Discussion}
\label{sec:discussion}

\subsection{Confirmation of Hypotheses}

\textbf{H1} (high entropy $\Rightarrow$ lower quality) is confirmed.
The Spearman correlation between entropy and \gls{PSNR} is consistently
negative, statistically significant after FDR correction, and robust
across all 15 methods, four sensors, and three entropy scales.
The robust regression coefficients for entropy predictors are all
negative and individually significant (\Cref{tab:robust-regression}),
confirming that the relationship persists after conditioning on method
identity and noise level.

\textbf{H2} (geostatistical/transform methods better in low-entropy areas)
is \TODO{partially / fully} confirmed.
\TODO{Discuss relative rank ordering in the low-entropy tercile.}

\textbf{H3} (significant spatial autocorrelation) is confirmed.
Moran's\,$I > 0$ for all methods at all tested patches, with
$p < 0.001$ in all cases. \gls{LISA} analysis reveals that HH error
clusters co-locate with textural boundaries and high-entropy cores.

\subsection{Practical Implications}

The entropy-performance relationship offers a principled pre-selection
criterion: before applying any gap-filling method, compute the local
entropy of available context pixels. If the mean gap-region entropy
exceeds a sensor-specific threshold (\TODO{calibrate from
\Cref{tab:psnr-entropy-tercile}}), consider:
(i) patch-based methods (non-local means, biharmonic) which exploit
global self-similarity rather than local smoothness;
(ii) \gls{CS} methods which are inherently sparsity-seeking; or
(iii) deep learning approaches not evaluated here.

For low-entropy (smooth) scenes, all methods perform comparably,
and the computationally cheapest option (bilinear) may suffice.

\subsection{Limitations}

\begin{enumerate}
 \item \textbf{Simulated gaps.} We use synthetic cloud masks derived
 from sensor cloud-probability layers. Real cloud edges may
 have different spatial statistics.
 \item \textbf{Temporal information not exploited.} Multi-temporal
 methods (temporal spline, DINEOF, Fourier) are excluded from
 the primary analysis because they require time-series stacks
 rather than single-image inputs. A separate temporal benchmark
 is warranted.
 \item \textbf{Deep learning baselines.} Four DL architectures are
 evaluated separately (\Cref{sec:results-dl}); a unified analysis
 remains future work.
 \item \textbf{Spatial resolution heterogeneity.} MODIS (500\,m) patches
 have fundamentally different texture statistics from Sentinel-2
 (10\,m). Sensor-specific thresholds may be required.
 \item \textbf{Entropy as a single predictor.} Entropy does not capture
 anisotropy, dominant frequency, or edge density. Future work
 could incorporate complementary texture descriptors.
\end{enumerate}

% ============================================================
\section{Conclusion}
\label{sec:conclusion}

We presented the first large-scale quantitative analysis of the
relationship between local Shannon entropy and classical gap-filling
performance in satellite imagery.
Over \TODO{77,916} test patches from four sensors, 15 methods, and four
noise levels, we showed that:
\begin{itemize}
 \item Local Shannon entropy is a statistically significant negative
 predictor of reconstruction quality (\gls{PSNR}, \gls{SSIM},
 \gls{RMSE}) for all 15 classical methods, across all tested
 entropy scales.
 \item The entropy-performance effect persists after conditioning on
 method identity, noise level, and satellite sensor via robust
 regression.
 \item Reconstruction errors are spatially autocorrelated and cluster
 in high-entropy zones, as confirmed by Moran's\,$I$ and \gls{LISA}.
\end{itemize}

These findings justify entropy-guided adaptive method selection and
provide a reproducible benchmark for future comparisons.
All code, configurations, and pre-processed patch manifests are released
at \url{https://github.com/meiazero/pdi-entropy-gapfilling}.

% ============================================================
\section*{Data Availability}

The preprocessed patch corpus (manifest CSV and numpy arrays) will be
deposited at \TODO{[Zenodo / institutional repository]} upon acceptance.
Raw imagery is openly available from ESA (Sentinel-2), USGS (Landsat),
and NASA LP DAAC (MODIS).

\section*{Author Contributions}

\TODO{CRediT statement.}

\section*{Competing Interests}

The authors declare no competing interests.

\section*{Acknowledgements}

\TODO{Funding sources, HPC access, etc.}

% ============================================================
\appendix

\section{Kruskal-Wallis Post-Hoc Pairwise Comparisons}
\label{app:posthoc}

\begin{table}[H]
 \centering
 \small
 \caption{%
 Pairwise Mann-Whitney $U$ tests (Bonferroni-corrected) for PSNR
 at noise-free condition. Cliff's $\delta$ effect sizes reported.
 Significant pairs ($p_{\mathrm{adj}} < 0.05$) marked with $^*$.
 }
 \label{tab:kw-posthoc}
 \begin{tabular}{llccc}
 \toprule
 Method A & Method B & $U$ & $p_{\mathrm{adj}}$ & Cliff's $\delta$\\
 \midrule
 \TODO{...} & & & &\\
 \bottomrule
 \end{tabular}
\end{table}

\section{Deep Learning Baseline Comparison}
\label{sec:results-dl}

\Cref{tab:dl-comparison} compares the top-5 classical methods
against four deep learning baselines
(Autoencoder, VAE, conditional GAN, Transformer)
on the same test set.

\begin{table}[H]
 \centering
 \small
 \caption{%
 Classical (top 5 by PSNR) vs. deep learning models.
 Metrics at noise-free condition; Sentinel-2 sensor.
 }
 \label{tab:dl-comparison}
 \begin{tabular}{lccccc}
 \toprule
 Model & PSNR (dB) & SSIM & RMSE & SAM & ERGAS\\
 \midrule
 \multicolumn{6}{l}{\textit{Classical -- top 5}}\\
 \TODO{Method 1} & & & & &\\
 \TODO{Method 2} & & & & &\\
 \TODO{Method 3} & & & & &\\
 \TODO{Method 4} & & & & &\\
 \TODO{Method 5} & & & & &\\
 \midrule
 \multicolumn{6}{l}{\textit{Deep Learning}}\\
 Autoencoder & & & & &\\
 VAE & & & & &\\
 cGAN & & & & &\\
 Transformer & & & & &\\
 \bottomrule
 \end{tabular}
\end{table}

\section{Supplementary Figures}
\label{app:supp}

Additional per-satellite scatterplots, LISA maps, and local metric
maps are available in the supplementary material.

% ============================================================


\end{document}
